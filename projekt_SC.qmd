---
title: "projekt_SC"
author: "DS, PT"
format: html
editor: visual
---

1.  Czego dotyczy
2.  Identyfikacja nielosowych składowych
    1.  trend - aproksymacja za pomocą wielomianu
    2.  sezonowość - Holt-Winters/ aproksymacja trendu za pomocą 2. wielomianu/SARlMA
3.  Identyfikacja (modelowanie) reszt
    1.  korelacje
    2.  stacjonarność
    3.  homoskedastyczność
    4.  Stacjonarny i homoskedastyczny -\> ARIMA
    5.  Niejednorodna wariancja i reszty nieskorelowane -\>GARCH
4.  Bezpośrednia identyfikacja przed dekompozycją: modele SARIMA (jeśli występuje okresowość)/ARlMA (niestacjonarność)

integracja zwykła i sezonowa

# Czego dotyczy projekt

Dane przedstawiają liczbę fabrycznie nowych samochodów osobowych zarejestrowanych po raz pierwszy na terytorium Polski. Są to dane kwartalne pochodzące z lat 2010 - 2022.

```{r, warning = F, message = F}
library(ggplot2)
library(tseries)
library(lmtest)
library(forecast)
```

```{r}
data <- read.csv(".\\pojazdy.csv", sep = ';')
data <- data[,-c(1,2,55)]
X <- matrix(t(matrix(data, ncol = 4, byrow = F)))
X <- as.numeric(X)
```

```{r}
plot(X, lwd = 2, type = "l", xlab = "czas", ylab = "liczba samochodów")
```

# Identyfikacja nielosowych składowych

## trend - aproksymacja za pomocą wielomianu

```{r}
apr_wiel <- function(szereg, stopien){
  t <- 1:length(szereg)
  macierz <- NULL
  for(i in 1:stopien){
    macierz <- cbind(macierz, t^i)}
  
  ramka <- data.frame(szereg, macierz)
  model <- lm(szereg~., data=ramka)

  plot(t, szereg, type="l", 
       main=paste("Dopasowanie wielomianem stopnia:", stopien), 
       ylab="liczba samochodów", xlab="czas")
  lines(t, model$fitted.values, col=2, lwd=1.5)
  Sys.sleep(1)}
```

Wybór stopnia wielomianu

```{r}
# czy wyświetlać wykresy
df <- NULL
for(j in 1:10) {
  x <- diff(X, differences = j)
  #plot(x, main=paste("różnice ", j, 'stopnia'),
      # col=2, type='l', lwd=2)
  #abline(h=0,col=1)
  m <- mean(x)
  sigma <- mean(x^2)/choose(2*j, j)
  df <- rbind(df, c(j,m,sigma))
}

df <- as.data.frame(df)
names(df) <- c('stopien','m', 'sigma2')
df

plot(df$stopien, df$sigma2, lty=1, lwd=2, pch=19, type='b')
```

(?) Wybieramy wielomian stopnia 4.

```{r}
apr_wiel(X, 4)
```

Zbudowanie modelu

```{r}
t <- 1:length(X)
model <- lm(X ~ t + I(t^2) + I(t^3) + I(t^4))
```

## sezonowość - Holt-Winters/ aproksymacja trendu za pomocą 2. wielomianu/SARlMA

## dekompozycja za pomocą funkcji Holt-Winters

Zbadam sezonowość metodą Holta-Wintersa. Podejrzewamy, że sezonowość jest kwartalna. Skorzystaliśmy z funkcji \`HoltWinters\` , w której wskazaliśmy że nasz model jest multiplikatywny, ponieważ wartości przez cały czas rosną, tym samym rośnie rozmiar sezonowych wahań.

```{r}
df <- as.vector(t(data)) %>% matrix(ncol = 4, byrow = F)  %>% t() %>% c()

do_18 <- as.vector(t(data)) %>% matrix(ncol = 4, byrow = F) %>% t() %>% c()
do_18 <- do_18[1:(length(do_18)-4* 5)]
ts_data_18 <- ts(do_18, frequency = 4, start = c(2010, 1))

ts_data <- ts(df, frequency = 4, start = c(2010, 1))
ts_data
```

```{r}
holt_winters <- HoltWinters(ts_data, seasonal = 'multiplicative')
holt_winters
```

bieżące obserwacje mają duży wpływ na zmianę szeregu czasowego (alpha 0.7)

Ostatnie obserwacje mają bardzo mały wpływ na zmianę trendu (beta 0.03)

Parametr gamma wynosi 0.3, co oznacza, że ostatnie obserwacje mają mały wpływ na zmiany wzorców sezonowych.

```{r}
plot(holt_winters)
```

```{r}
przewidywania <- forecast(holt_winters, h=12) # przewiduje 12 kolejnych kwartałów
plot(przewidywania)
```

Są duże widełki w przewidywaniu przyszłych wartości. Jest to zapewne spowodowane spadkami i stabilizacją w ostatnich latach. Dla porównania poniżej przedstawiamy ten sam model, jednak dla danych bez ostatnich 5 lat (do 2018 roku):

```{r}
holt_winters_2018 <- HoltWinters(ts_data_18, seasonal = 'multiplicative')
holt_winters_2018
przewidywania_2018 <- forecast(holt_winters_2018, h=12) # przewiduje 12 kolejnych kwartałów
plot(przewidywania_2018)
```

Przez ostatnie spadki i stabilizaje w danych, przedział ufności dla przyszłych danych jest szerszy, zakładając zarówno mocny spadek jak i wzrost w sprzedaży aut osobowych.

```{r}
reszty_hw <- residuals(holt_winters) %>% as.vector()
plot(reszty_hw)
abline(a = 0, b=0, col='red')
```

```{r}
acf(reszty_hw)
```

# Identyfikacja (modelowanie) reszt

## korelacje

wielomian

```{r}
# nie ma korelacji 1 rzędu, wyższych już są
bgtest(model, order = 1)

# są korelacje
dwtest(model)
```

## stacjonarność

```{r}
adf.test(X)
kpss.test(X)
```

Na podstawie obu testów stwierdzamy, że szereg nie jest stacjonarny.

## homoskedastyczność

```{r}
gqtest(model)
bptest(model)
```

nie ma podstaw do odrzucenia homoskedastycznosci

## Niejednorodna wariancja i reszty nieskorelowane -\>GARCH

```{r}
GARCH_fit <- function(x) {
  t <- 1:length(x)
  mdl <- lm(x~t)
  test_bp_p.val <- bptest(mdl)$p.value
  if (test_bp_p.val<0.05) {
    ARCH_order <- GARCH_order <- AIC_value <- NULL
    df <- NULL
    for(p in 1:3) {
      for(q in 0:3) {
        mod <- garch(x, order = c(q,p)) # tu odwrócona wartość
        ARCH_order <- c(ARCH_order,p)
        GARCH_order <- c(GARCH_order,q)
        AIC_value <- c(AIC_value,AIC(mod))
      }
    }
    
    df <- data.frame(ARCH_order, GARCH_order, AIC_value)
    k <- which.min(df$AIC_value)
    napis <- paste('dopasowujemy modelem GARCH(',ARCH_order[k],',',GARCH_order[k],')')
  }
  else {
    napis <- "szereg jednorodny"
  }
  plot(x, type='l', main= napis)
  print(df)
}
```

```{r}
GARCH_fit(df)

mod <- garch(df, order=c(1,3))
summary(mod)
```

Test jarque bera -\> odrzucamy hipotezę o normalnym rozkładzie reszt (może przez ten outlier w 2020)

test Box-Ljunga -\> nie mamy podstaw do odrzucenia hipotezy o braku autokorelacji

```{r}
plot(mod)
```

# Bezpośrednia identyfikacja przed dekompozycją: modele SARIMA (jeśli występuje okresowość)

```{r}
df
auto_arima <- auto.arima(df) # 0 1 2
auto_arima$model
auto_arima$fitted %>% as.vector() %>% plot(type='l', col='red')
lines(df)

auto_arima$model$phi #wsp. autoregresji
auto_arima$model$theta #wsp. sredniej ruchomej
auto_arima$model$Delta #stopien integracji
```

# Różnicowanie

```{r}
roznicowanie <- diff(df)
plot(roznicowanie, type='l')
abline(b=0, a=0, col='red')
```

```{r}
adf.test(diff(df))
kpss.test(diff(df))
```

Po różnicowaniu szereg jest stacjonarny
